{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# machine learning\n",
    "import sklearn\n",
    "from sklearn import metrics, linear_model, svm\n",
    "import xgboost\n",
    "import lightgbm\n",
    "\n",
    "# other\n",
    "import gc\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "import functools\n",
    "import random\n",
    "from numerapi import NumerAPI\n",
    "from timeit import default_timer\n",
    "import re\n",
    "from scipy.stats import spearmanr\n",
    "import time\n",
    "\n",
    "# save variables\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# my utils\n",
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 15:22:10,343 INFO numerapi.utils: target file already exists\n",
      "2022-07-27 15:22:10,345 INFO numerapi.utils: download complete\n",
      "2022-07-27 15:22:11,589 INFO numerapi.utils: target file already exists\n",
      "2022-07-27 15:22:11,591 INFO numerapi.utils: download complete\n"
     ]
    }
   ],
   "source": [
    "napi = NumerAPI()\n",
    "current_round = napi.get_current_round()\n",
    "\n",
    "# filenames = napi.list_datasets()\n",
    "\n",
    "napi.download_dataset('v4/live.parquet', f'v4/live_{current_round}.parquet')\n",
    "napi.download_dataset('v4/live_int8.parquet', f'v4/live_int8_{current_round}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and columns to read\n",
    "\n",
    "- feature sets: `all`, `small`, `medium`, `v2_equivalent_features`, `v3_equivalent_features`, `fncv3_features`\n",
    "- feature groups: `features_all[0:210]`, `features_all[210:420]`, `features_all[420:630]`, `features_all[630:840]`, `features_all[840:1050]`, `features_all[1050:1191]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('v4/features.json', 'r') as f:\n",
    "#     feature_metadata = json.load(f)\n",
    "\n",
    "# features_all = list(feature_metadata['feature_stats'].keys())\n",
    "# features_small = feature_metadata['feature_sets']['small']\n",
    "# features_medium = feature_metadata['feature_sets']['medium']\n",
    "# features_v2 = feature_metadata['feature_sets']['v2_equivalent_features']\n",
    "# features_v3 = feature_metadata['feature_sets']['v3_equivalent_features']\n",
    "# features_fncv3 = feature_metadata['feature_sets']['fncv3_features']\n",
    "\n",
    "# features = features_all\n",
    "# target = 'target_nomi_v4_20'\n",
    "# n_features = len(features)\n",
    "\n",
    "# read_columns = ['era', 'data_type'] + features + [target] \n",
    "\n",
    "# df_feature_metadata = pd.DataFrame(feature_metadata['feature_stats'])\n",
    "# df_feature_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.read_parquet('v4/train_int8.parquet', columns=read_columns)\n",
    "# df_train['era'] = df_train['era'].astype('int32')\n",
    "# df_train.info(memory_usage='deep')\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation + Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_validation = pd.read_parquet('v4/validation_int8.parquet', columns=read_columns)\n",
    "# df_validation['era'] = df_validation['era'].astype('int32')\n",
    "# df_validation.info(memory_usage='deep')\n",
    "# df_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = df_validation.loc[df_validation['data_type'] == 'test']\n",
    "# df_test.info(memory_usage='deep')\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_live = pd.read_parquet('v4/live_int8.parquet', columns=read_columns)\n",
    "# df_live.info(memory_usage='deep')\n",
    "# df_live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of examples as a function of the era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = df_train.groupby('era').size().index.values\n",
    "# y_train = df_train.groupby('era').size().values\n",
    "# x_validation = df_validation[df_validation.data_type == 'validation'].groupby('era').size().index.values\n",
    "# y_validation = df_validation[df_validation.data_type == 'validation'].groupby('era').size().values\n",
    "# x_test = df_validation[df_validation.data_type == 'test'].groupby('era').size().index.values\n",
    "# y_test = df_validation[df_validation.data_type == 'test'].groupby('era').size().values\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x_train, y_train, label='train')\n",
    "# ax.plot(x_validation, y_validation, label='validation')\n",
    "# ax.plot(x_test, y_test, label='test')\n",
    "# ax.set_xlabel('era')\n",
    "# ax.set_ylabel('number of examples')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_correlations = df_train[df_train.era==1][features].corr()\n",
    "# plt.figure(figsize = (8,8))\n",
    "# plt.imshow(feature_correlations)\n",
    "# for a in [210, 420, 630, 840, 1050]:\n",
    "#     plt.axvline(a, color = 'orange')\n",
    "#     plt.axhline(a, color = 'orange')\n",
    "\n",
    "# feature_groups = [features[0:210],\n",
    "#                   features[210:420],\n",
    "#                   features[420:630],\n",
    "#                   features[840:1050],\n",
    "#                   features[1050:-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation of feature with target as a function of the era"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eras_train = df_train.era.unique()\n",
    "# target_correlations = np.array([np.corrcoef(df_train[df_train.era == e][[target] + features].T)[0, 1:] for e in eras_train])\n",
    "# target_correlations = pd.DataFrame(target_correlations)\n",
    "# target_correlations.rename(columns = dict(enumerate(features)), inplace = True)\n",
    "# target_correlations.insert(0, 'era', eras_train)\n",
    "# joblib.dump(target_correlations, 'saved-variables/target_correlations.pkl')\n",
    "# target_correlations = joblib.load('saved-variables/target_correlations.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = target_correlations['era']\n",
    "# y = target_correlations['feature_untidy_withdrawn_bargeman']\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(x, y)\n",
    "# ax.set_xlabel('era')\n",
    "# ax.set_ylabel('correlation with target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models\n",
    "\n",
    "In this section we test many models without caring about hyperparameters (i.e., just use the defaults for each model). The goal is to identify which models look the most promising. We want to consider the time to train, as well as\n",
    "\n",
    "Performance metrics:\n",
    "\n",
    "- correlation\n",
    "- rank-correlation / spearman-correlation\n",
    "- `sklearn.metrics.r2_score`\n",
    "- `sklearn.metrics.mean_squared_error`\n",
    "\n",
    "Models worth trying at first\n",
    "\n",
    "- `sklearn.linear_model.LinearRegression()`\n",
    "- `sklearn.linear_model.LogisticRegression()`\n",
    "- `sklearn.linear_model.SGDRegressor()` (Stochastic Gradient Descent regressor)\n",
    "- `sklearn.linear_model.Lasso()`\n",
    "- `sklearn.linear_model.ElasticNet()`\n",
    "- `sklearn.linear_model.Ridge()`\n",
    "- `sklearn.svm.SVR(kernel='rbf')` (Support Vector Machine / Regression)\n",
    "- `sklearn.svm.SVR(kernel='linear')`\n",
    "- `lightgbm.LGBMRegressor()`\n",
    "- `xgboost.XGBRegressor()`\n",
    "\n",
    "Ensembles\n",
    "\n",
    "- `sklearn.ensemble.RandomForestRegressor()`\n",
    "- `sklearn.ensemble.ExtraTreesRegressor()`\n",
    "- `sklearn.ensemble.BaggingRegressor()`\n",
    "- `sklearn.ensemble.AdaBoostRegressor()`\n",
    "- `sklearn.ensemble.GradientBoostingRegressor()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`BlockRegressor` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockRegressor:\n",
    "    def __init__(self, base_regressor):\n",
    "        self.base_regressor = base_regressor\n",
    "        self.times = np.zeros((4, 6))\n",
    "        self.base_models = np.array([[base_regressor() for j in range(6)] for i in range(4)])\n",
    "\n",
    "    def fit(self, df):\n",
    "        for i, j in product(range(4), range(6)):\n",
    "            X = X_block(df, i, j)\n",
    "            y = y_rows(df, i)\n",
    "            t0 = default_timer()\n",
    "            self.base_models[i, j].fit(X, y)\n",
    "            self.times[i, j] = default_timer() - t0\n",
    "\n",
    "    def predict(self, df):\n",
    "        y_mean = 0\n",
    "        for i, j in product(range(4), range(6)):\n",
    "            y_mean += self.base_models[i, j].predict(X_cols(df, j))\n",
    "        y_mean /= 24\n",
    "        return y_mean\n",
    "\n",
    "    def score(self, df, y_pred = None):\n",
    "        y_true = df[TARGET].to_numpy()\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    def corr(self, df, y_pred = None):\n",
    "        y_true = df[TARGET].to_numpy()\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return np.corrcoef(y_true, y_pred)[0,1]\n",
    "\n",
    "    def r_corr(self, df, y_pred = None):\n",
    "        y_true = df[TARGET].to_numpy()\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return spearmanr(y_true, y_pred)[0]\n",
    "\n",
    "    def n_corr(self, df, y_pred = None):\n",
    "        y_true = df[TARGET].to_numpy()\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        y_eras = pd.DataFrame({'era': df.era, 'y': y_pred})\n",
    "        r_pred = y_eras.groupby(y_eras.era).apply(lambda x: x.rank(pct=True, method=\"first\"))['y'].to_numpy()\n",
    "        return np.corrcoef(y_true, r_pred)[0,1]\n",
    "\n",
    "    def mse(self, df, y_pred = None):\n",
    "        y_true = df[TARGET].to_numpy()\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return metrics.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    def to_dataframe(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        \n",
    "        df_dict = {'model': [], 'i': [], 'j': [], 'time': [], 'r2': [], 'corr': [], 'r_corr': [], 'n_corr': [], 'mse': []}\n",
    "\n",
    "        df_dict['model'].append(string_from_class(self.base_regressor))\n",
    "        df_dict['i'].append(-1)\n",
    "        df_dict['j'].append(-1)\n",
    "        df_dict['time'].append(np.sum([self.times[i, j] for i, j in product(range(4), range(6))]))\n",
    "        df_dict['r2'].append(self.score(df, y_pred))\n",
    "        df_dict['corr'].append(self.corr(df, y_pred))\n",
    "        df_dict['r_corr'].append(self.r_corr(df, y_pred))\n",
    "        df_dict['n_corr'].append(self.n_corr(df, y_pred))\n",
    "        df_dict['mse'].append(self.mse(df, y_pred))\n",
    "        \n",
    "        for i, j in product(range(4), range(6)):\n",
    "            model = self.base_models[i, j]\n",
    "            X = X_block(df, i, j)\n",
    "            y_true = y_rows(df, i)\n",
    "            y_pred = model.predict(X)\n",
    "            t = self.times[i, j]\n",
    "            e0 = df['era'][0]\n",
    "            e1 = df['era'][-1]\n",
    "            y_eras = pd.DataFrame({'era': df[df.era.isin(era_subsample(e0, e1, i))].era, 'y': y_pred})\n",
    "            r_pred = y_eras.groupby(y_eras.era).apply(lambda x: x.rank(pct=True, method=\"first\"))['y'].to_numpy()\n",
    "\n",
    "            df_dict['model'].append(string_from_class(self.base_regressor))\n",
    "            df_dict['i'].append(i)\n",
    "            df_dict['j'].append(j)\n",
    "            df_dict['time'].append(t)\n",
    "            df_dict['r2'].append(metrics.r2_score(y_true, y_pred))\n",
    "            df_dict['corr'].append(np.corrcoef(y_true, y_pred)[0,1])\n",
    "            df_dict['r_corr'].append(spearmanr(y_true, y_pred)[0])\n",
    "            df_dict['n_corr'].append(np.corrcoef(y_true, r_pred)[0,1])\n",
    "            df_dict['mse'].append(metrics.mean_squared_error(y_true, y_pred))\n",
    "\n",
    "        return pd.DataFrame(df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model.LinearRegression()`\n",
    "\n",
    "- `n_corr = 0,059704610597046286`\n",
    "- `time = 106,95175510000081`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c = linear_model.LinearRegression\n",
    "\n",
    "# df = pd.read_parquet('v4/train_int8.parquet', columns=READ_COLUMNS)\n",
    "# df['era'] = df['era'].astype('int32')\n",
    "\n",
    "# model = BlockRegressor(c)\n",
    "# model.fit(df)\n",
    "\n",
    "# y_pred = model.predict(df)\n",
    "# results = model.to_dataframe(df, y_pred)\n",
    "\n",
    "# joblib.dump(results, 'saved-variables/target_correlations.pkl')\n",
    "# results.to_parquet(f'saved-variables/{string_from_class(c)}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model.LogisticRegression()`\n",
    "\n",
    "This does not work because `LogisticRegression` is actually a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model.SGDRegressor()` (Stochastic Gradient Descent regressor)\n",
    "\n",
    "- `n_corr = 0,045239964085015669`\n",
    "- `time = 895,23360329999923`\n",
    "- `r2 = 0,0020271945744916309`, but individual models have negative `r2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model.Lasso()`\n",
    "\n",
    "- getting nonsense in `Lasso` and `ElasticNet`:\n",
    "- negative `r2` (for ensemble)\n",
    "- can't compute `r_corr`\n",
    "- `n_corr = 0,00055597628201768787`, which is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model.ElasticNet()`\n",
    "\n",
    "- Same thing is happening as in `Lasso`\n",
    "- Check what these algorithms do: understand why they give such garbage results (negative `r2`, bad `n_corr`, can't compute `r_corr`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.linear_model.Ridge()`\n",
    "\n",
    "- `r2 = 0,0035569099916116231`, bad\n",
    "- `n_corr = 0,059704588286116231`, OK\n",
    "- `time = 29,314123199990718`, very good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.svm.SVR(kernel='rbf')` (Support Vector Machine / Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn.svm.SVR(kernel='linear')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lightgbm.LGBMRegressor()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xgboost.XGBRegressor()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EraEnsemble:\n",
    "    def __init__(self, base_regressor):\n",
    "        self.base_regressor = base_regressor\n",
    "        self.base_models = [base_regressor() for i in range(4)]\n",
    "        self.time_fit = 0\n",
    "        self.time_pred = 0\n",
    "\n",
    "    def fit(self, df):\n",
    "        t0 = default_timer()\n",
    "        for i in range(4):\n",
    "            X = X_(df, eras = i)\n",
    "            y = y_(df, eras = i)\n",
    "            self.base_models[i].fit(X, y)\n",
    "        self.time_fit = default_timer() - t0\n",
    "\n",
    "    def predict(self, df):\n",
    "        t0 = default_timer()\n",
    "        y_mean = 0\n",
    "        for i in range(4):\n",
    "            y_mean += self.base_models[i].predict(X_(df))\n",
    "        y_mean /= 4\n",
    "        self.time_pred = default_timer() - t0\n",
    "        return y_mean\n",
    "\n",
    "    def score(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return metrics.r2_score(y_(df), y_pred)\n",
    "\n",
    "    def corr(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return np.corrcoef(y_(df), y_pred)[0,1]\n",
    "\n",
    "    def r_corr(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return spearmanr(y_(df), y_pred)[0]\n",
    "\n",
    "    def mse(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        return metrics.mean_squared_error(y_(df), y_pred)\n",
    "\n",
    "    def n_corr(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        y_eras = pd.DataFrame({'era': df.era, 'y': y_pred})\n",
    "        r_pred = y_eras.groupby(y_eras.era).apply(rank_pct)['y']\n",
    "        return np.corrcoef(y_(df), r_pred)[0,1]\n",
    "\n",
    "    def scores(self, df, y_pred = None):\n",
    "        if y_pred is None:\n",
    "            y_pred = self.predict(df)\n",
    "        d = dict()\n",
    "        d['model'] = string_from_class(self.base_regressor)\n",
    "        d['time_fit'] = self.time_fit\n",
    "        d['time_pred'] = self.time_pred\n",
    "        d['r2'] = self.score(df, y_pred)\n",
    "        d['corr'] = self.corr(df, y_pred)\n",
    "        d['r_corr'] = self.r_corr(df, y_pred)\n",
    "        d['n_corr'] = self.n_corr(df, y_pred)\n",
    "        d['mse'] = self.mse(df, y_pred)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('v4/train_int8.parquet', columns=READ_COLUMNS)\n",
    "df['era'] = df['era'].astype('int32')\n",
    "model = EraEnsemble(linear_model.LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_0 = model.scores(df, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1 = model.scores(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d202d1b6c0c7975210c24a4862339e0f7f90d66cb89735f264f6c4d5c4350e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
