{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerai API\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "# data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# other\n",
    "import gc\n",
    "import json\n",
    "from tqdm import trange\n",
    "from itertools import product\n",
    "import functools\n",
    "import random\n",
    "from timeit import default_timer\n",
    "import re\n",
    "import time\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from varname import nameof\n",
    "from datetime import datetime\n",
    "\n",
    "# save variables\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# my utils\n",
    "from utils import rank_pct, numerai_score, exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napi = NumerAPI()\n",
    "round = napi.get_current_round()\n",
    "\n",
    "filenames = napi.list_datasets()\n",
    "\n",
    "napi.download_dataset('v4/features.json', '../data/features.json')\n",
    "napi.download_dataset('v4/train_int8.parquet', '../data/train.parquet')\n",
    "napi.download_dataset('v4/validation_int8.parquet', '../validation.parquet')\n",
    "napi.download_dataset('v4/live_int8.parquet', f'../data/live_{round}.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('v4/features.json', 'r') as f:\n",
    "    FEATURE_METADATA = json.load(f)\n",
    "del f\n",
    "\n",
    "FEATURES_L = list(FEATURE_METADATA['feature_stats'].keys())\n",
    "FEATURES_M = FEATURE_METADATA['feature_sets']['medium']\n",
    "FEATURES_S = FEATURE_METADATA['feature_sets']['small']\n",
    "FEATURES_2 = FEATURE_METADATA['feature_sets']['v2_equivalent_features']\n",
    "FEATURES_3 = FEATURE_METADATA['feature_sets']['v3_equivalent_features']\n",
    "FEATURES_N = FEATURE_METADATA['feature_sets']['fncv3_features']\n",
    "\n",
    "ERA = 'era'\n",
    "DATA = 'data_type'\n",
    "Y_TRUE = 'target_nomi_v4_20'\n",
    "Y_PRED = 'target_prediction'\n",
    "Y_RANK = 'prediction' \n",
    "\n",
    "X_COLS = FEATURES_L\n",
    "COLUMNS = [ERA, DATA] + X_COLS + [Y_TRUE]\n",
    "\n",
    "df_feature_metadata = pd.DataFrame(FEATURE_METADATA['feature_stats'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EraSubsampler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EraSubsampler(BaseEstimator):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y, eras):\n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        e0 = eras.min()\n",
    "        e1 = eras.max() + 1\n",
    "        self.model = [deepcopy(self.estimator) for i in range(4)]\n",
    "        for i in trange(4):\n",
    "            self.model[i].fit(X[eras.isin(np.arange(e0 + i, e1, 4))], \n",
    "                              y[eras.isin(np.arange(e0 + i, e1, 4))])\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        y_pred = 0\n",
    "        for i in trange(4):\n",
    "            y_pred += self.model[i].predict(X)\n",
    "        y_pred /= 4\n",
    "        return y_pred\n",
    "\n",
    "    # TODO: make score function be the numerai_score (depends on groups)\n",
    "    def score(self, X, y):\n",
    "        return r2_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "X_COLS = FEATURES_L\n",
    "COLUMNS = [ERA, DATA] + X_COLS + [Y_TRUE]\n",
    "df_trn = pd.read_parquet('v4/train_int8.parquet', columns=COLUMNS)\n",
    "df_trn[ERA] = df_trn[ERA].astype('int32')\n",
    "# df_trn = df_trn[df_trn[ERA] <= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "params = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'max_leaves': 2**5,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'device': 'gpu',\n",
    "    # 'gpu_id': 0,\n",
    "    # 'tree_method': 'gpu_hist',\n",
    "}\n",
    "# xgb = EraSubsampler(XGBRegressor(**params))\n",
    "xgb = EraSubsampler(LGBMRegressor(**params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "xgb.fit(df_trn[X_COLS], df_trn[Y_TRUE], df_trn[ERA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and score on training set\n",
    "df_trn[Y_PRED] = xgb.predict(df_trn[X_COLS])\n",
    "df_trn[Y_RANK] = df_trn[Y_PRED].rank(pct=True)\n",
    "ns_trn = numerai_score(df_trn[Y_TRUE], df_trn[Y_PRED], df_trn[ERA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define validation set\n",
    "# df_val = pd.read_parquet('v4/validation_int8.parquet', columns=COLUMNS)\n",
    "# df_val = df_val[df_val[DATA].isin(['validation'])]\n",
    "# df_val[ERA] = df_val[ERA].astype('int32')\n",
    "# # df_val = df_val[df_val[ERA] <= 575 + 20]\n",
    "\n",
    "# # predict and score on validation set\n",
    "# df_val[Y_PRED] = xgb.predict(df_val[X_COLS])\n",
    "# df_val[Y_RANK] = df_val[Y_PRED].rank(pct=True)\n",
    "# ns_val = numerai_score(df_val[Y_TRUE], df_val[Y_PRED], df_val[ERA])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define live set\n",
    "# df_liv = pd.read_parquet(f'v4/live_int8_{round}.parquet', columns=COLUMNS)\n",
    "\n",
    "# # predict on validation set\n",
    "# df_liv[Y_PRED] = xgb.predict(df_liv[X_COLS])\n",
    "# df_liv[Y_RANK] = df_liv[Y_PRED].rank(pct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save variables\n",
    "# now = datetime.now().strftime('%Y%m%d%H%M')\n",
    "# joblib.dump(xgb, f'saved-variables/lgbm_{now}.pkl')\n",
    "# df_val[Y_RANK].to_csv(f'predictions/lgbm_validation_predictions_{round}_{now}.csv')\n",
    "# df_liv[Y_RANK].to_csv(f'predictions/lgbm_live_predictions_{round}_{now}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {'estimator__' + k: [v] for k, v in params.items()}\n",
    "# xgbGS = GridSearchCV(EraSubsampler(XGBRegressor()), param_grid)\n",
    "\n",
    "# xgbGS.fit(df_trn[X_COLS], df_trn[Y_TRUE], groups=df_trn[ERA], **{'eras': df_trn[ERA]})\n",
    "\n",
    "# bst = xgbGS.best_estimator_\n",
    "\n",
    "# df_trn['bst_' + Y_PRED] = bst.predict(df_trn[X_COLS])\n",
    "# df_trn['bst_' + Y_RANK] = df_trn['bst_' + Y_PRED].rank(pct=True)\n",
    "# ns_bst = numerai_score(df_trn[Y_TRUE], df_trn['bst_' + Y_PRED], df_trn[ERA])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature neutralization class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Neutralizer(BaseEstimator):\n",
    "#     # in this class: X = [era | features]\n",
    "#     def __init__(self, estimator, n_features, alpha):\n",
    "#         self.estimator = estimator\n",
    "#         self.n_features = n_features\n",
    "#         self.alpha = alpha\n",
    "\n",
    "#     def fit(self, X, y, **fit_params):\n",
    "#         X, y = check_X_y(X, y, accept_sparse=True)\n",
    "#         X = X[X_COLS]\n",
    "#         self.estimator.fit(X, y, **fit_params)\n",
    "#         self.is_fitted_ = True\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         X = check_array(X, accept_sparse=True)\n",
    "#         check_is_fitted(self, 'is_fitted_')\n",
    "#         eras = X[ERA]\n",
    "#         X = X[X_COLS]\n",
    "#         y_pred = self.estimator.predict(X)\n",
    "#         if self.alpha == 0:\n",
    "#             return y_pred\n",
    "#         y_linr = 0\n",
    "#         y_neut = y_pred - self.alpha * y_linr\n",
    "#         return y_neut\n",
    "\n",
    "#     def score(self, X, y):\n",
    "#         X = check_array(X, accept_sparse=True)\n",
    "#         check_is_fitted(self, 'is_fitted_')\n",
    "#         return r2_score(y, self.predict(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d202d1b6c0c7975210c24a4862339e0f7f90d66cb89735f264f6c4d5c4350e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
