{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerai API\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "# data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# other\n",
    "import gc\n",
    "import json\n",
    "from tqdm import trange\n",
    "from itertools import product\n",
    "import functools\n",
    "import random\n",
    "from timeit import default_timer\n",
    "import re\n",
    "import time\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from varname import nameof\n",
    "from datetime import datetime\n",
    "\n",
    "# save variables\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# my utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class:\n",
    "- write code\n",
    "- test that it works alone\n",
    "- test that it works (when chained with previous classes)\n",
    "- test that it works if passed to a GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_COLS = FEATURES_L\n",
    "COLUMNS = [ERA, DATA] + X_COLS + Y_COLS\n",
    "\n",
    "df = pd.read_parquet('data/train.parquet', columns=COLUMNS)\n",
    "df[ERA] = df[ERA].astype('int32')\n",
    "df = df[df[ERA] <= 8]\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 2**5,\n",
    "    'colsample_bytree': 0.1,\n",
    "    # 'device': 'gpu',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatureSubsampler class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureSubsampler com n_features = 0\n",
    "\n",
    "# model_0 = LGBMRegressor(**params)\n",
    "# model_0 = FeatureSubsampler(model_0, n_features_per_group=0)\n",
    "# model_0.fit(df[X_COLS], df[Y_TRUE])\n",
    "# score_0 = model_0.score(df[X_COLS], df[Y_TRUE])\n",
    "\n",
    "# model_1 = LGBMRegressor(**params)\n",
    "# model_1.fit(df[X_COLS], df[Y_TRUE])\n",
    "# score_1 = model_1.score(df[X_COLS], df[Y_TRUE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FeatureSubsampler com n_features = 210 vs manual\n",
    "\n",
    "# model_0 = LGBMRegressor(**params)\n",
    "# model_0 = FeatureSubsampler(model_0, n_features_per_group=210)\n",
    "# model_0.fit(df[X_COLS], df[Y_TRUE])\n",
    "# df['y_pred_0'] = model_0.predict(df[X_COLS])\n",
    "\n",
    "# model_1 = LGBMRegressor(**params)\n",
    "# n = len(X_COLS)\n",
    "# l = 210\n",
    "# k = ceil(n / l)\n",
    "# y_pred = 0\n",
    "# for i in range(k):\n",
    "#     feature_indices = range(i * l, min((i + 1) * l, n))\n",
    "#     features = [X_COLS[i] for i in feature_indices]\n",
    "#     model_1.fit(df[features], df[Y_TRUE])\n",
    "#     y_pred += model_1.predict(df[features])\n",
    "# y_pred /= k\n",
    "# df['y_pred_1'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model_0\n",
      "predicting with model_0\n",
      "training model_1 (grid search)\n",
      "predicting with model_1 (best estimator)\n"
     ]
    }
   ],
   "source": [
    "# FeatureSubsampler no GridSearch\n",
    "\n",
    "# model_0 = LGBMRegressor(**params)\n",
    "# model_0 = FeatureSubsampler(model_0, n_features_per_group=210)\n",
    "# print('training model_0')\n",
    "# model_0.fit(df[X_COLS], df[Y_TRUE])\n",
    "# print('predicting with model_0')\n",
    "# df['y_pred_0'] = model_0.predict(df[X_COLS])\n",
    "\n",
    "# param_grid = {'estimator__' + k: [v] for k, v in params.items()}\n",
    "# model_1 = LGBMRegressor(**params)\n",
    "# model_1 = FeatureSubsampler(model_1, n_features_per_group=210)\n",
    "# model_1 = GridSearchCV(model_1, param_grid)\n",
    "# print('training model_1 (grid search)')\n",
    "# model_1.fit(df[X_COLS], df[Y_TRUE])\n",
    "# model_1 = model_1.best_estimator_\n",
    "# print('predicting with model_1 (best estimator)')\n",
    "# df['y_pred_1'] = model_1.predict(df[X_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model_0\n",
      "predicting with model_0\n",
      "training model_1 (grid search)\n",
      "predicting with model_1 (best estimator)\n"
     ]
    }
   ],
   "source": [
    "# FeatureSubsampler -> EraSubsampler no GridSearch\n",
    "\n",
    "# model_0 = LGBMRegressor(**params)\n",
    "# model_0 = FeatureSubsampler(model_0, n_features_per_group=210)\n",
    "# model_0 = EraSubsampler(model_0, n_subsamples=4)\n",
    "# print('training model_0')\n",
    "# model_0.fit(df[X_COLS], df[Y_TRUE], eras=df[ERA])\n",
    "# print('predicting with model_0')\n",
    "# df['y_pred_0'] = model_0.predict(df[X_COLS])\n",
    "\n",
    "# param_grid = {'estimator__estimator__' + k: [v] for k, v in params.items()}\n",
    "# model_1 = LGBMRegressor(**params)\n",
    "# model_1 = FeatureSubsampler(model_1, n_features_per_group=210)\n",
    "# model_1 = EraSubsampler(model_1, n_subsamples=4)\n",
    "# model_1 = GridSearchCV(model_1, param_grid)\n",
    "# print('training model_1 (grid search)')\n",
    "# model_1.fit(df[X_COLS], df[Y_TRUE], eras=df[ERA])\n",
    "# model_1 = model_1.best_estimator_\n",
    "# print('predicting with model_1 (best estimator)')\n",
    "# df['y_pred_1'] = model_1.predict(df[X_COLS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Era(Feature) vs Feature(Era)\n",
    "\n",
    "# model_0 = LGBMRegressor(**params)\n",
    "# model_0 = FeatureSubsampler(model_0, n_features_per_group=210)\n",
    "# model_0 = EraSubsampler(model_0, n_subsamples=4)\n",
    "# model_0.fit(df[X_COLS], df[Y_TRUE], eras=df[ERA])\n",
    "# df['y_pred_0'] = model_0.predict(df[X_COLS])\n",
    "\n",
    "# model_1 = LGBMRegressor(**params)\n",
    "# model_1 = EraSubsampler(model_1, n_subsamples=4)\n",
    "# model_1 = FeatureSubsampler(model_1, n_features_per_group=210)\n",
    "# model_1.fit(df[X_COLS], df[Y_TRUE], eras=df[ERA])\n",
    "# df['y_pred_1'] = model_1.predict(df[X_COLS])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d202d1b6c0c7975210c24a4862339e0f7f90d66cb89735f264f6c4d5c4350e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
