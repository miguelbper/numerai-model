{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerai API\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "# data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# other\n",
    "import gc\n",
    "import json\n",
    "from tqdm import trange\n",
    "from itertools import product\n",
    "import functools\n",
    "import random\n",
    "from timeit import default_timer\n",
    "import re\n",
    "import time\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from varname import nameof\n",
    "from datetime import datetime\n",
    "\n",
    "# save variables\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# my utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_COLS = FEATURES_L\n",
    "COLUMNS = [ERA] + X_COLS + Y_COLS\n",
    "Y_ALT = 'target_paul_v4_20'\n",
    "\n",
    "df = pd.read_parquet('data/train.parquet', columns=COLUMNS)\n",
    "df[ERA] = df[ERA].astype('int32')\n",
    "eras = df[ERA]\n",
    "e0 = eras.min()\n",
    "e1 = eras.max() + 1\n",
    "df = df[df[ERA].isin(np.arange(e0, e1, 4))]\n",
    "dfnan = df.isna().any()\n",
    "# print(df.dtypes[df.columns[-1]])\n",
    "df[np.isnan(df)] = 0.5\n",
    "\n",
    "params_lgbm = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 2**5,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'device': 'gpu',\n",
    "}\n",
    "\n",
    "params_xgb = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'max_leaves': 2**5,\n",
    "    'colsample_bytree': 0.1,\n",
    "    'gpu_id': 0,\n",
    "    'tree_method': 'gpu_hist',\n",
    "}\n",
    "\n",
    "X = df[X_COLS]\n",
    "y = df[Y_TRUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "\n",
    "def nempty_subsets(iterable):\n",
    "    s = list(iterable)\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(1, len(s)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,), (1,), (2,), (0, 1), (0, 2), (1, 2), (0, 1, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(nempty_subsets(range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1,), (2,), (3,), (1, 2), (1, 3), (2, 3), (1, 2, 3)]\n"
     ]
    }
   ],
   "source": [
    "# model = LGBMRegressor(**params)\n",
    "# model = EraSubsampler(model)\n",
    "# model = MultiTargetTrainer(model)\n",
    "\n",
    "e = 0 \n",
    "spl = TimeSeriesSplitGroups()\n",
    "\n",
    "corr_dict = {\n",
    "    'subset': [],\n",
    "    'fold_1': [],\n",
    "    'fold_2': [],\n",
    "    'fold_3': [],\n",
    "    'fold_4': [],\n",
    "    'fold_5': [],\n",
    "}\n",
    "\n",
    "i = 0\n",
    "for trn, val in spl.split(X, y, e):\n",
    "    i += 1\n",
    "    print(f'in iteration {i}/5 of CV')\n",
    "    X_val = X.iloc[val]\n",
    "    y_val = y.iloc[val]\n",
    "    e_val = e.iloc[val]\n",
    "    # X_trn = X.iloc[trn]\n",
    "    # y_trn = y.iloc[trn]\n",
    "    # e_trn = e.iloc[trn]\n",
    "\n",
    "    # print('\\ttraining model')\n",
    "    # model.fit(X_trn, y_trn, eras=e_trn)\n",
    "    # joblib.dump(model, f'model-0/saved-variables/multi_target_fold_{i}.pkl')\n",
    "    model = joblib.load(f'model-0/saved-variables/multi_target_fold_{i}.pkl')\n",
    "\n",
    "    # print('\\tcomputing predictions')\n",
    "    y_val_pred = model.model.predict(X_val)\n",
    "    joblib.dump(y_val_pred, f'model-0/saved-variables/y_val_pred_{i}.pkl')\n",
    "    # model = joblib.load(f'model-0/saved-variables/y_val_pred_{i}.pkl')\n",
    "\n",
    "    for subset in nempty_subsets(range(10)):\n",
    "\n",
    "        y_pred = 0 # choose cols of y_val_pred in subset, take average\n",
    "        y_true = y_val\n",
    "\n",
    "        c = corr(y_true, y_pred, rank_b=e_val)\n",
    "\n",
    "        corr_dict[f'fold_{i}'].append(c)\n",
    "        if i == 1:\n",
    "            corr_dict['subset'].append(subset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d202d1b6c0c7975210c24a4862339e0f7f90d66cb89735f264f6c4d5c4350e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
