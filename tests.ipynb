{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerai API\n",
    "from numerapi import NumerAPI\n",
    "\n",
    "# data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# stats\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# other\n",
    "import gc\n",
    "import json\n",
    "from tqdm import trange\n",
    "from itertools import product\n",
    "import functools\n",
    "import random\n",
    "from timeit import default_timer\n",
    "import re\n",
    "import time\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from varname import nameof\n",
    "from datetime import datetime\n",
    "\n",
    "# save variables\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "# my utils\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 193, f = feature_palpebral_univalve_pennoncel\n",
      "i = 208, f = feature_unsustaining_chewier_adnoun\n",
      "i = 403, f = feature_brainish_nonabsorbent_assurance\n",
      "i = 418, f = feature_coastal_edible_whang\n",
      "i = 613, f = feature_disprovable_topmost_burrower\n",
      "i = 628, f = feature_trisomic_hagiographic_fragrance\n",
      "i = 823, f = feature_queenliest_childing_ritual\n",
      "i = 838, f = feature_censorial_leachier_rickshaw\n",
      "i = 1033, f = feature_daylong_ecumenic_lucina\n",
      "i = 1048, f = feature_steric_coxcombic_relinquishment\n"
     ]
    }
   ],
   "source": [
    "# invalid feature indices\n",
    "\n",
    "for f in INVALID_FEATURES:\n",
    "    i = FEATURES_L.index(f)\n",
    "    print(f'i = {i}, f = {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each class:\n",
    "- write code\n",
    "- test that it works alone\n",
    "- test that it works (when chained with previous classes)\n",
    "- test that it works if passed to a GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_COLS = FEATURES_S\n",
    "COLUMNS = [ERA] + X_COLS + Y_COLS\n",
    "Y_ALT = 'target_paul_v4_20'\n",
    "\n",
    "df = pd.read_parquet('data/train.parquet', columns=COLUMNS)\n",
    "df[ERA] = df[ERA].astype('int32')\n",
    "df = df[df[ERA] <= 8]\n",
    "dfnan = df.isna().any()\n",
    "# print(df.dtypes[df.columns[-1]])\n",
    "df[np.isnan(df)] = 0.5\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 2000,\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 5,\n",
    "    'num_leaves': 2**5,\n",
    "    'colsample_bytree': 0.1,\n",
    "    # 'device': 'gpu',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature neutralizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureNeutralizer(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimator, n_features, alpha):\n",
    "        self.estimator = estimator\n",
    "        self.n_features = n_features\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        X, y = check_X_y(X, y, accept_sparse=True)\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        self.is_fitted_ = True\n",
    "        return self\n",
    "    \n",
    "    def compute_y_pred(self, X):\n",
    "        # checks\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        # computations\n",
    "        self.y_pred = self.estimator.predict(X)\n",
    "\n",
    "    def compute_y_linr(self, X, y_pred, groups):\n",
    "        # checks\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        if not hasattr(self, 'y_pred'):\n",
    "            self.compute_y_pred(X)\n",
    "        # computations\n",
    "        # n riskiest features\n",
    "        # auxiliary function\n",
    "        # result\n",
    "        y_linr = 0\n",
    "        self.y_linr = y_linr\n",
    "\n",
    "    def predict(self, X, y_pred, groups):\n",
    "        # checks\n",
    "        X = check_array(X, accept_sparse=True)\n",
    "        check_is_fitted(self, 'is_fitted_')\n",
    "        if not hasattr(self, 'y_pred'):\n",
    "            self.compute_y_pred(X)\n",
    "        if not hasattr(self, 'y_linr'):\n",
    "            self.compute_y_linr(X, y_pred, groups)\n",
    "        # computations\n",
    "        return self.y_pred - self.alpha * self.y_linr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d202d1b6c0c7975210c24a4862339e0f7f90d66cb89735f264f6c4d5c4350e67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
